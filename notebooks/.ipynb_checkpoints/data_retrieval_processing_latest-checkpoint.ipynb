{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for retrieving, processing, and saving the latest UK rainfall data via the EA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, date\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and time: 2023-05-21 21:03:40\n"
     ]
    }
   ],
   "source": [
    "# printing current date and time\n",
    "print('Date and time: ' + str(datetime.today().replace(microsecond=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list present working directory\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data retrieval functions\n",
    "\n",
    "# function to retrieve data on rainfall stations\n",
    "def get_data_stations(parameter_name = None,\n",
    "                 parameter = None,\n",
    "                 qualifier = None,\n",
    "                 label = None,\n",
    "                 town = None,\n",
    "                 catchment_name = None,\n",
    "                 river_name = None,\n",
    "                 station_reference = None,\n",
    "                 rloi_id = None,\n",
    "                 search = None,\n",
    "                 lat = None,\n",
    "                 long = None,\n",
    "                 d = None,\n",
    "                 type = None,\n",
    "                 status = None):\n",
    "    \"\"\"Get details of rainfall monitoring stations from the EA API\n",
    "    \n",
    "      Query parameter details:\n",
    "    \n",
    "      :param parameter_name: Return only those stations which measure parameters with the given name, for example Rainfall, Water Level or Flow.\n",
    "      :param parameter: Return only those stations which measure parameters with the given short form name, for example rainfall, level or flow.\n",
    "      :param qualifier: Return only those stations which measure parameters with qualifier. Useful qualifiers are Stage and Downstream Stage (for stations such as weirs which measure levels at two locations), Groundwater for groundwater levels as opposed to river levels and Tidal Level for tidal levels.\n",
    "      :param label: Return only those stations whose label is exactly as given.\n",
    "      :param town: Return only those stations whose town is as given. Not all stations have an associated town.\n",
    "      :param catchment_name: Return only those stations whose catchment name is exactly as given. Not all stations have an associated catchment area.\n",
    "      :param river_name: Return only those stations whose river name is exactly as given. Not all stations have an associated river name.\n",
    "      :param station_reference: Return only those stations whose reference identifier is as given. The station reference is an internal identifier used by the Environment Agency.\n",
    "      :param rloi_id: Return only the station (if there is one) whose RLOIid (River Levels on the Internet identifier) matches.\n",
    "      :param search: Return only those stations whose label contains the given value.\n",
    "      :param lat: Return those stations whose location falls within d km of the given latitude/longitude (in WGS84 coordinates), this may be approximated by a bounding box.\n",
    "      :param long: Return those stations whose location falls within d km of the given latitude/longitude (in WGS84 coordinates), this may be approximated by a bounding box.\n",
    "      :param d: Return those stations whose location falls within d km of the given latitude/longitude (in WGS84 coordinates), this may be approximated by a bounding box.\n",
    "      :param type: Return only those stations of the given type, where type can be one of \"SingleLevel\", \"MultiTraceLevel\", \"Coastal\", \"Groundwater\" or \"Meteorological\"\n",
    "      :param status: Return only those stations with the given status. Can be one of \"Active\", \"Closed\" or \"Suspended\".\n",
    "      \"\"\"\n",
    "    \n",
    "    # URL of the UK EA API\n",
    "    api_url = \"https://environment.data.gov.uk/flood-monitoring/id/stations\"\n",
    " \n",
    "    # build a dictionary of the query parameters\n",
    "    params =  {'parameterName': parameter_name,\n",
    "                'parameter': parameter,\n",
    "                'qualifier': qualifier,\n",
    "                'label': label,\n",
    "                'town': town,\n",
    "                'catchmentName': catchment_name,\n",
    "                'riverName': river_name,\n",
    "                'stationReference': station_reference,\n",
    "                'RLOIid': rloi_id,\n",
    "                'search': search,\n",
    "                'lat': lat,\n",
    "                'long': long,\n",
    "                'dist': d,\n",
    "                'type': type,\n",
    "                'status': status\n",
    "              }\n",
    "    \n",
    "    # getting data on stations from the EA API\n",
    "    response = requests.get(api_url, \n",
    "                            params = params)\n",
    "\n",
    "    # ensuring that cookies are allowed\n",
    "    #response = requests.get(api_url, params, cookies=response.cookies)\n",
    "    \n",
    "    # extracting JSON data from the response container\n",
    "    data = response.json()\n",
    "\n",
    "    # extracting the items elements and loading data to a pandas data frame\n",
    "    stations = pd.DataFrame(data[\"items\"])\n",
    "\n",
    "    return(stations)\n",
    "\n",
    "\n",
    "# function to retrieve data on rainfall measures\n",
    "def get_data_measures(parameter_name = None,\n",
    "                     parameter = None,\n",
    "                     qualifier = None,\n",
    "                     station_reference = None,\n",
    "                     station = None,\n",
    "                     search = None):\n",
    "    \"\"\"Get details of measures available from the EA API\n",
    "\n",
    "       :param parameter_name: Return only measures for parameters with the given name, for example Water Level or Flow.\n",
    "       :param parameter: Return only measures for parameters with the given short form name, for example level or flow.\n",
    "       :param qualifier: Return only those measures with qualifier. Useful qualifiers are Stage and Downstream Stage (for stations such as weirs which measure levels at two locations), Groundwater for groundwater levels as opposed to river levels and Tidal Level for tidal levels.\n",
    "       :param station_reference: Return only those measures which are available from the station with the given reference identifier.\n",
    "       :param station: Return only those measures which are available from the station with the given URI.\n",
    "       :param search: Return only those measures whose label contains the given value.\n",
    "    \"\"\"\n",
    "    api_url = \"http://environment.data.gov.uk/flood-monitoring/id/measures\"\n",
    "    \n",
    "     # build a dictionary of the query parameters\n",
    "    params = {'parameterName': parameter_name,\n",
    "    'parameter': parameter,\n",
    "    'qualifier': qualifier,\n",
    "    'stationReference': station_reference,\n",
    "    'station': station,\n",
    "    'search': search\n",
    "    }\n",
    "    \n",
    "    # getting data about measures from the EA API\n",
    "    response = requests.get(api_url, \n",
    "                            params)\n",
    "\n",
    "    # ensuring that cookies are allowed\n",
    "    #response = requests.get(api_url, params, cookies=response.cookies)\n",
    "    \n",
    "    # extracting JSON data from the response container\n",
    "    data = response.json()\n",
    "\n",
    "    # extracting the items elements and loading data to a pandas data frame\n",
    "    measures = pd.DataFrame(data[\"items\"])\n",
    "\n",
    "    return(measures)\n",
    "\n",
    "# function to retrieve data on rainfall readings\n",
    "def get_data_readings(       limit = None,\n",
    "                             date = None, \n",
    "                             startdate = None, \n",
    "                             enddate = None,\n",
    "                             since = None, \n",
    "                             latest = False,\n",
    "                             today = False, \n",
    "                             sorted = True,\n",
    "                             parameter_name = None,\n",
    "                             parameter = None,\n",
    "                             qualifier = None,\n",
    "                             station_reference = None,\n",
    "                             station = None,\n",
    "                             search = None):\n",
    "    \"\"\"Get readings for a given measure from the EA API\n",
    "\n",
    "      :param measure_id: EA API measure id\n",
    "      :param limit: Maximum number of records to return. Defaults to 500. Max 10000.\n",
    "      :param date: Return all the readings taken on the specified day.\n",
    "      :param startdate: Return the readings taken on the specified range of days. Date format 2023-05-17.\n",
    "      :param enddate: Return the readings taken on the specified range of days. Date format 2023-05-17.\n",
    "      :param since: Return the readings taken since the given date time (not inclusive), up to the specified limit. If no limit is given then a default limit of 500 will be used. Typically when tracking a particular measurement then use the dateTime of the last retrieved value as the since parameter to find any new readings. Will accept a simple date value such as 2016-09-07 which will be interpreted as 2016-09-07T:00:00:00Z. The latter (with timestamp) is also accepted.\n",
    "      :param latest: Return only the latest reading.\n",
    "      :param today: Return only all readings from today.\n",
    "      :param sorted: Order the array of returned readings into descending order by date, this done before the limits is applied thus enabling you to fetch the most recent n readings.     \n",
    "      :param parameter_name: Return only measures for parameters with the given name, for example Water Level or Flow.\n",
    "      :param parameter: Return only measures for parameters with the given short form name, for example level or flow.\n",
    "      :param qualifier: Return only those measures with qualifier. Useful qualifiers are Stage and Downstream Stage (for stations such as weirs which measure levels at two locations), Groundwater for groundwater levels as opposed to river levels and Tidal Level for tidal levels.\n",
    "      :param station_reference: Return only those measures which are available from the station with the given reference identifier.\n",
    "      :param station: Return only those measures which are available from the station with the given URI.\n",
    "      :param search: Return only those measures whose label contains the given value.\n",
    "  \"\"\"\n",
    "    # Set True/False argument to blank or None so it is handled correctly\n",
    "    if latest:\n",
    "        latest = ''\n",
    "    else:\n",
    "        latest = None\n",
    "        \n",
    "    if today:\n",
    "        today = ''\n",
    "    else:\n",
    "        today = None\n",
    "  \n",
    "    if sorted:\n",
    "        sorted = ''\n",
    "    else:\n",
    "        sorted = None\n",
    "    \n",
    "    # build a dictionary of the query parameters\n",
    "    params = {'_limit': limit,\n",
    "    'date': date,\n",
    "    'startdate': startdate,\n",
    "    'enddate': enddate,\n",
    "    'since': since, \n",
    "    'latest': latest,\n",
    "    'today': today,\n",
    "    '_sorted': sorted,       \n",
    "    'parameterName': parameter_name,\n",
    "    'parameter': parameter,\n",
    "    'qualifier': qualifier,\n",
    "    'stationReference': station_reference,\n",
    "    'station': station,\n",
    "    'search': search\n",
    "    }\n",
    "  \n",
    "    api_url = 'http://environment.data.gov.uk/flood-monitoring/data/readings?parameter=rainfall'\n",
    "    \n",
    "    # getting data about readings from the EA API\n",
    "    response = requests.get(api_url, params)\n",
    "    \n",
    "    # ensuring that cookies are allowed\n",
    "    #response = requests.get(api_url, params, cookies=response.cookies)\n",
    "\n",
    "    # extracting JSON data from the response container\n",
    "    data = response.json()\n",
    "\n",
    "    # extracting the items elements and loading data to a pandas data frame\n",
    "    readings = pd.DataFrame(data[\"items\"])\n",
    "\n",
    "    return(readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the rainfall stations, measures, and readings data \n",
    "rainfall_stations_data = get_data_stations(parameter='rainfall')\n",
    "rainfall_measures_data = get_data_measures(parameter='rainfall')\n",
    "rainfall_readings_data_latest = get_data_readings(latest=True, sorted=True, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of station data: (997, 19)\n",
      "Shape of measures data: (1023, 13)\n",
      "Shape of latest readings data: (919, 4)\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of entries for each dataset\n",
    "print('Shape of station data: ' + str(rainfall_stations_data.shape))\n",
    "print('Shape of measures data: ' + str(rainfall_measures_data.shape))\n",
    "print('Shape of latest readings data: ' + str(rainfall_readings_data_latest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in the rainfall stations data: 2\n",
      "Number of duplicates in the rainfall measures data: 25\n",
      "Number of duplicates in the rainfall readings data: 0\n",
      "Shape of datasets after dropping duplicates:\n",
      "Shape of station data: (995, 19)\n",
      "Shape of measures data: (998, 13)\n",
      "Shape of latest readings data: (919, 4)\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicates in each data frame by 'station_id' or 'stationReference' and dropping them\n",
    "print('Number of duplicates in the rainfall stations data: ' + str(rainfall_stations_data[rainfall_stations_data.duplicated(['stationReference'])].shape[0]))\n",
    "print('Number of duplicates in the rainfall measures data: ' + str(rainfall_measures_data[rainfall_measures_data.duplicated(['stationReference'])].shape[0]))\n",
    "print('Number of duplicates in the rainfall readings data: ' + str(rainfall_readings_data_latest[rainfall_readings_data_latest.duplicated(['@id'])].shape[0]))\n",
    "\n",
    "# dropping the duplicates and retaining the first values - this can be investigated later and rows with more entries can be\n",
    "# kept to retain the most amount of information\n",
    "rainfall_stations_data.drop_duplicates(subset=['stationReference'], keep='first', inplace = True)\n",
    "rainfall_measures_data.drop_duplicates(subset=['stationReference'], keep='first', inplace = True)\n",
    "rainfall_readings_data_latest.drop_duplicates(subset=['@id'], keep='first', inplace = True)\n",
    "\n",
    "# resetting the indices of the data frames\n",
    "rainfall_stations_data.reset_index(drop = True, inplace = True)\n",
    "rainfall_measures_data.reset_index(drop = True, inplace = True)\n",
    "rainfall_readings_data_latest.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Checking the number of entries for each dataset after dropping duplicates\n",
    "print('Shape of datasets after dropping duplicates:')\n",
    "print('Shape of station data: ' + str(rainfall_stations_data.shape))\n",
    "print('Shape of measures data: ' + str(rainfall_measures_data.shape))\n",
    "print('Shape of latest readings data: ' + str(rainfall_readings_data_latest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the datasets to be combined\n",
    "\n",
    "# extracting the 'measure' variable across datasets, which will serve as the UID primary key for combination\n",
    "\n",
    "# stations data: creating the 'measure' variable by extracting values from the 'measures' dictionary\n",
    "rainfall_stations_data['measure'] = rainfall_stations_data['measures'].copy()\n",
    "for i in range(rainfall_stations_data.shape[0]):\n",
    "    rainfall_stations_data.at[i,'measure'] = next(iter(rainfall_stations_data['measures'][i][0].values()))\n",
    "    \n",
    "# measures data: renaming the '@id' column to 'measures' to enable merging and better readability\n",
    "rainfall_measures_data.rename(columns = {'@id': 'measure'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n"
     ]
    }
   ],
   "source": [
    "# merging the 3 dataframes for rainfall stations, measures, and readings data\n",
    "\n",
    "# left join of readings with measures to keep all readings and outer join of resulting df with stations to keep\n",
    "# details of non-responsive stations as well\n",
    "rainfall_combined_data_latest = rainfall_readings_data_latest.merge(rainfall_measures_data,on='measure', how='left').merge(rainfall_stations_data,on='measure', how='outer')\n",
    "\n",
    "# viewing the shape of the resulting df\n",
    "print(rainfall_combined_data_latest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the combined dataframe:(1000, 17)\n"
     ]
    }
   ],
   "source": [
    "# further data cleaning\n",
    "\n",
    "# filling missing values for station reference from secondary duplicate variable (from the stations dataframe)\n",
    "rainfall_combined_data_latest.loc[rainfall_combined_data_latest['stationReference_x'].isnull(),'stationReference_x'] = rainfall_combined_data_latest['stationReference_y']\n",
    "\n",
    "# dropping duplicate and redundant columns\n",
    "rainfall_combined_data_latest = rainfall_combined_data_latest.drop(columns=['@id_x',\n",
    "                                                              'label_x',\n",
    "                                                              'measure',\n",
    "                                                              'latestReading',\n",
    "                                                              'notation_x',\n",
    "                                                              'station',\n",
    "                                                              '@id_y',                                                \n",
    "                                                              'stationReference_y',\n",
    "                                                              'measures',\n",
    "                                                              'notation_y',\n",
    "                                                              # columns relevant only for river data\n",
    "                                                              'catchmentName',\n",
    "                                                              'dateOpened',\n",
    "                                                              'riverName',\n",
    "                                                              'stageScale',\n",
    "                                                              'status',\n",
    "                                                              'town',\n",
    "                                                              'wiskiID',\n",
    "                                                              'datumOffset',\n",
    "                                                              'RLOIid'\n",
    "                                                             ])\n",
    "\n",
    "# renaming columns\n",
    "rainfall_combined_data_latest.rename(columns =   {'dateTime': 'date_and_time',\n",
    "                                           'value': 'reading_value',\n",
    "                                           'parameter': 'parameter_id',\n",
    "                                           'parameterName': 'parameter_name',\n",
    "                                           'period': 'reading_period',\n",
    "                                           'qualifier': 'reading_qualifier',\n",
    "                                           'stationReference_x': 'station_id',\n",
    "                                           'unit':'reading_unit_id',\n",
    "                                           'unitName':'reading_unit_name',\n",
    "                                           'valueType':'reading_value_type',\n",
    "                                           'easting':'station_easting',\n",
    "                                           'northing': 'station_northing',\n",
    "                                           'gridReference': 'station_grid_reference',\n",
    "                                           'label_y': 'station_type',\n",
    "                                           'lat': 'station_latitude',\n",
    "                                           'long':'station_longitude',\n",
    "                                           'valueType':'reading_value_type',\n",
    "                                           'gridReference': 'station_grid_reference'},\n",
    "                              inplace = True)\n",
    "\n",
    "# separating date and time variables\n",
    "\n",
    "# creating datetime object\n",
    "rainfall_combined_data_latest['date_and_time'] = pd.to_datetime(rainfall_combined_data_latest['date_and_time'])\n",
    "\n",
    "# creating date variable\n",
    "rainfall_combined_data_latest['date'] = rainfall_combined_data_latest['date_and_time'].dt.date\n",
    "\n",
    "# creaating time variable\n",
    "rainfall_combined_data_latest['time'] = rainfall_combined_data_latest['date_and_time'].dt.time\n",
    "                                                           \n",
    "# reordering columns and dropping 'date_and_time' column\n",
    "rainfall_combined_data_latest = rainfall_combined_data_latest[[   'date',\n",
    "                                                    'time',\n",
    "                                                    'station_id',\n",
    "                                                    'station_type',\n",
    "                                                    'station_grid_reference',\n",
    "                                                    'station_latitude',\n",
    "                                                    'station_longitude',\n",
    "                                                    'station_easting',\n",
    "                                                    'station_northing',\n",
    "                                                    'parameter_id',\n",
    "                                                    'parameter_name',\n",
    "                                                    'reading_qualifier',\n",
    "                                                    'reading_value',\n",
    "                                                    'reading_unit_id',\n",
    "                                                    'reading_unit_name',\n",
    "                                                    'reading_value_type',\n",
    "                                                    'reading_period'\n",
    "                                               ]]\n",
    "\n",
    "# viewing the shape of the resulting combined df\n",
    "print(\"Shape of the combined dataframe:\" + str(rainfall_combined_data_latest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__date__: date  \n",
    "__time__: time  \n",
    "__station_id__: station identifier  \n",
    "__station_type__: type of station  \n",
    "__station_grid_reference__: grid reference for the station, rounded to a 100m grid  \n",
    "__station_latitude__: latitude coordinates of station  \n",
    "__station_longitude__: longitude coordinates of station  \n",
    "__station_easting__: easting coordinates of station  \n",
    "__station_northing__: northing coordinates of station  \n",
    "__parameter_id__: short name/id of the quantity being measured  \n",
    "__parameter_name__: name of the quantity being measured  \n",
    "__reading_qualifier__: a qualifier for the quantity being measured, \"Tipping Bucket Raingauge\" for rainfall  \n",
    "__reading_value__: the value of the reading for the associated measurement  \n",
    "__reading_unit_id__: unit id/url for the reading  \n",
    "__reading_unit_name__: unit name for the reading  \n",
    "__reading_value_type__: type of measurement, e.g., total, mean, etc.  \n",
    "__reading_period__: the period between successive readings, in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stations with no recent rainfall measurements: 81\n",
      "\n",
      "IDs of the respective stations:\n",
      "\n",
      "['4163' 'E1310' '0' '1117' '45101' '270400TP' '055223' 'E15520' 'E1965'\n",
      " 'E11060' '008632' '000032' 'E23535' '019356' 'E43041' '266474TP' '577805'\n",
      " 'E22876' 'E11040' '000102TP' '49106' '592848' '4103' '550148' '1795'\n",
      " 'E23657' '50108' 'E7120' 'E22735' '238097TP' '593321' 'E2450' '562992'\n",
      " 'E1691' '45157' '007533' '584098' 'E14880' 'E7190' '46101' 'E2859'\n",
      " '476898_TG_333' '246847TP' 'E24775' '568363' 'E1928' '585022' 'E24585'\n",
      " '605382' '563599' '55000A' 'E24141' '562811' 'E24499' 'E5720' '45108_'\n",
      " 'E1711' '4527' '6666LO' '1409Lucas' '4549' '4548' 'E5650' '7015' '1607'\n",
      " '47176' '1338' '1750' '1810' '1408' 'Coldw1' 'Mitch1' 'Edgeh1' 'Dubbs1'\n",
      " '585122_' '2102SO' '575092______________________________________'\n",
      " '574786______________________________________' '062916' 'E60880' 'NE063']\n"
     ]
    }
   ],
   "source": [
    "# check if there are any stations without recent rainfall measurements and list their Station IDs\n",
    "\n",
    "# list total stations with no recent rainfall measurements\n",
    "print( \"Total stations with no recent rainfall measurements: \" + str(rainfall_combined_data_latest['reading_value'].isna().sum()))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('IDs of the respective stations:')\n",
    "\n",
    "print('')\n",
    "\n",
    "# listing their IDs\n",
    "print(rainfall_combined_data_latest[rainfall_combined_data_latest['reading_value'].isna() == True]['station_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN value check with an assert statement\n",
    "#assert len(rainfall_combined_data_latest[rainfall_combined_data_latest['reading_value'].isna() == True]['station_id'].tolist()) == 0, f\"0 expected, got: {len(rainfall_combined_data_latest[rainfall_combined_data_latest['reading_value'].isna() == True]['station_id'].tolist())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stations without latitude coordinates: 11\n",
      "\n",
      "IDs of the respective stations:\n",
      "\n",
      "['024121' '282947TP' 'E7040' nan '068416' nan 'E23500' '305111' '6666LO'\n",
      " '4549' '4548']\n"
     ]
    }
   ],
   "source": [
    "# listing stations without latitude (can also be checked for longitude)\n",
    "print( \"Total stations without latitude coordinates: \" + str(rainfall_combined_data_latest['station_latitude'].isna().sum()))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('IDs of the respective stations:')\n",
    "\n",
    "print('')\n",
    "\n",
    "# listing their IDs\n",
    "print(rainfall_combined_data_latest[rainfall_combined_data_latest['station_latitude'].isna() == True]['station_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in the combined data frame: 2\n",
      "Shape of combined data after dropping duplicates: (998, 17)\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate stations by station ID on combined data frame (they could have come from the responses df)\n",
    "print('Number of duplicates in the combined data frame: ' + str(rainfall_combined_data_latest[rainfall_combined_data_latest.duplicated(['station_id'])].shape[0]))\n",
    "\n",
    "# dropping the duplicates and retaining the first values - this can be investigated later and rows with more entries can be\n",
    "# kept to retain the most amount of information\n",
    "rainfall_combined_data_latest.drop_duplicates(subset=['station_id'], keep='first', inplace = True)\n",
    "\n",
    "# resetting the indices of the data frames\n",
    "rainfall_combined_data_latest.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Checking the number of entries for the dataset after dropping duplicates\n",
    "print('Shape of combined data after dropping duplicates: ' + str(rainfall_combined_data_latest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving combined dataset as csv and excel files\n",
    "rainfall_combined_data_latest.to_csv(f'../data/rainfall_data_latest_{date.today()}.csv')\n",
    "rainfall_combined_data_latest.to_excel(f'../data/rainfall_data_latest_{date.today()}.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
